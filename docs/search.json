[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "\nSobre\n",
    "section": "",
    "text": "Sobre\n\nA minha formação (gradução e mestrado) é em economia na Universidade Federal do Ceará - UFC. Desde a graduação venho trabalhando com análise de dados e econometria. Também participei de algumas competições no Kaggle. Inicialmente, a minha linguagem de trabalho era o Stata. Contudo, a partir de 2014 comecei a usar o R como linguangem principal. Também trabalhei com o Python em alguns projetos do Kaggle.\n\nProjetos Públicos\n\n\nPacote em R para simulações utilizando o modelo de comércio desenvolvido em Caliendo e Parro (2015). cp2015\nHtmlwidget para R para utilização da biblioteca D3plus (v1). D3plusR\nLivro: Ciência de Dados com R - Introdução com Saulo Guerra, Robert MacDonnell e Sillas Gonzaga."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Paulo Oliveira",
    "section": "",
    "text": "Eu sou o Paulo. Minha formação é em economia. Minha área de interesse é análise de dados em geral, como simulação com base em modelos econômicos, econometria e aprendizado de máquina."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "16 de jul. de 2023\n            6 minutos\n        \n\n        \n          \n          Dados de comércio exterior do Brasil com Arrow e Duckdb\n        \n        \n          Baixe a base completa e faça consultas localmente\n        \n        \n          \n            \n              python\n            \n            \n            \n              Dados\n            \n            \n        \n      \n    \n    \n    \n      \n        \n          \n          9 de jun. de 2023\n            3 minutos\n        \n\n        \n          \n          Visualizações de mapas interativos com o D3plusR\n        \n        \n          Integrando o D3plusR com o geobr\n        \n        \n          \n            \n              R\n            \n            \n            \n              Visualização de dados\n            \n            \n        \n      \n    \n    \n    \n      \n        \n          \n          16 de mar. de 2023\n            8 minutos\n        \n\n        \n          \n          Binscatter\n        \n        \n          Visualizando relações entre variáveis com binned scatterplots\n        \n        \n          \n            \n              R\n            \n            \n            \n              Econometria\n            \n            \n            \n              Visualização de dados\n            \n            \n        \n      \n    \n    \n    \n      \n        \n          \n          20 de dez. de 2022\n            7 minutos\n        \n\n        \n          \n          Predições de Resultados de Futebol\n        \n        \n          Vamos documentar uma abordagem de predição de partidas de futebol utilizando modelos de regressões de Poisson.\n        \n        \n          \n            \n              R\n            \n            \n            \n              Modelos preditivos\n            \n            \n        \n      \n    \n    \n\n\nNenhum item correspondente"
  },
  {
    "objectID": "posts/teste.html",
    "href": "posts/teste.html",
    "title": "teste",
    "section": "",
    "text": "3 + 43\n\n[1] 46"
  },
  {
    "objectID": "posts/hello-world.html",
    "href": "posts/hello-world.html",
    "title": "Hello World",
    "section": "",
    "text": "3 + 43\n\n[1] 46\n\n\n\nmtcars |>\n  ggplot2::ggplot() +\n  ggplot2::aes(y = mpg, x = hp) +\n  ggplot2::geom_point()"
  },
  {
    "objectID": "posts/teste/index.html",
    "href": "posts/teste/index.html",
    "title": "Hello World",
    "section": "",
    "text": "2 + 2\n\n[1] 4\n\n\n\nmtcars |>\n  ggplot2::ggplot() +\n  ggplot2::aes(x = hp, y = mpg) +\n  ggplot2::geom_point()\n\n\n\nggplot2::ggsave(filename = \"teste.png\")\n\nSaving 7 x 5 in image\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer bibendum, massa vitae fermentum ultrices, odio magna pretium nunc, sit amet euismod est justo viverra mauris. Proin vestibulum euismod nulla, sed ornare magna porta at. Etiam in elit felis. Morbi condimentum, odio ut fringilla accumsan, elit arcu faucibus lorem, ac mattis odio mi non sem. Morbi laoreet neque eu mi lobortis, nec rhoncus elit feugiat. Donec blandit lacinia arcu sit amet rhoncus. Vivamus pharetra egestas dolor ac scelerisque. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Nam vestibulum augue ut hendrerit dapibus. Morbi at sodales eros. Phasellus gravida ut turpis at faucibus. Sed efficitur vulputate mattis. Aenean laoreet lorem in libero pulvinar, eget bibendum lacus dictum. Aenean eget sem in metus malesuada euismod.\nEtiam et ex mi. In finibus tristique laoreet. Suspendisse commodo sem vitae placerat consequat. Vivamus maximus auctor eros ac finibus. Duis maximus a nisi ut rhoncus. Maecenas rutrum, erat ac consectetur rhoncus, nisl sapien ullamcorper tortor, nec egestas lectus leo non magna. Aliquam facilisis ultrices lacus sed euismod. Maecenas ultricies vestibulum porttitor.\nEtiam tristique mollis quam, sit amet venenatis nibh interdum ac. Donec non urna lectus. Aliquam erat volutpat. Suspendisse pretium vel eros ac ullamcorper. Donec ut pulvinar enim, quis bibendum massa. Curabitur ornare elementum sagittis. Ut sagittis sem quis magna facilisis, eu fringilla ante sollicitudin. Fusce purus dolor, rutrum in ultricies varius, ultrices ut quam. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae;\nEtiam euismod vehicula sapien, vel ullamcorper nisl congue vel. Nam rutrum lectus ac consequat tincidunt. Etiam consectetur tortor massa, id hendrerit ex lacinia sit amet. Praesent turpis diam, viverra eu maximus non, mollis sed mauris. In maximus in ante quis consequat. In vel felis magna. Suspendisse tristique mi sed suscipit maximus.\nPellentesque vehicula eget ante ac consectetur. Quisque sed blandit nibh. Nullam consectetur vulputate pulvinar. Aliquam lacinia eros sit amet mauris lobortis, ac hendrerit est ultricies. Ut dapibus libero eros, et aliquet leo laoreet vitae. Aenean congue euismod tincidunt. Sed faucibus, mauris ut maximus tempor, lectus nisi sollicitudin tortor, et tristique ligula lectus ultrices ex. Vestibulum posuere lorem nec felis tincidunt consectetur. Nulla libero nunc, scelerisque vitae facilisis id, aliquet vel tellus. Aliquam cursus ipsum et viverra congue. Curabitur at commodo quam, a molestie risus. Nulla pharetra dolor nisl, non tempus quam porttitor eu.\n\n2 + 2\n\n[1] 4"
  },
  {
    "objectID": "index.html#projetos",
    "href": "index.html#projetos",
    "title": "Olá,",
    "section": "Projetos",
    "text": "Projetos\n\nPacote em R para simulações utilizando o modelo de comércio desenvolvido em Caliendo e Parro (2015). cp2015\nHtmlwidget para R para utilização da biblioteca D3plus (v1). D3plusR\nLivro: Ciência de Dados com R - Introdução com Saulo Guerra, Robert MacDonnell e Sillas Gonzaga."
  },
  {
    "objectID": "index.html#projetoss",
    "href": "index.html#projetoss",
    "title": "Paulo Oliveira",
    "section": "Projetoss",
    "text": "Projetoss\n\nPacote em R para simulações utilizando o modelo de comércio desenvolvido em Caliendo e Parro (2015). cp2015\nHtmlwidget para R para utilização da biblioteca D3plus (v1). D3plusR\nLivro: Ciência de Dados com R - Introdução com Saulo Guerra, Robert MacDonnell e Sillas Gonzaga."
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html",
    "href": "posts/2022-12-20-bipoisson/index.html",
    "title": "Predições de Resultados de Futebol",
    "section": "",
    "text": "Durante a Copa do Mundo de futebol de 2022, o interesse por predições de resultados de futebol aumentou consideravelmente. Neste sentido, este post irá demonstrar uma abordagem simples que pode gerar resultados razoáveis. O modelo utilizado neste post é baseado no trabalho The Methodology of Red, a Football Forecasting Model from theUniversity of Reading de J. James Reade.\nBasicamente, o autor utiliza um modelo de Poisson para prever as probabilidades de gols marcados por cada time. A partir dessas probabilidades, é possível estimar também a chance de vitória, empate ou derrota de cada time. Como variáveis, iremos utilizar o Elo Rating de cada time e uma variável que indica se o jogo ocorreu em campo neutro ou não. O modelo a ser estimado para cada time é: \\[ Y_{ijt}^n = \\exp\\left(\\alpha^n + \\beta_1^n R_{it} + \\beta_2^n R_{jt} + \\beta_3^n N_{ijt} \\right) \\varepsilon_{ijt}^n,~~~~ n \\in \\{time1, time2\\}, \\] em que \\(Y_{ijt}^n\\) representa o número de gols marcados pelo time \\(n\\) (time 1 ou time2) em uma partida entre o time \\(i\\) (time 1) e o time \\(j\\) (time 2) na data \\(t\\). As variáveis \\(R_{it}\\) e \\(R_{jt}\\) representam, respectivamente, os ratings dos times \\(i\\) e \\(j\\) antes da partida de data \\(t\\). Por último, a variável \\(N_{ijt}\\) é um variável dummy que indica se a partida foi realizada em um campo neutro. Reforçando, iremos estimar dois modelos: um para o time 1 e outro para o time 2."
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#dados",
    "href": "posts/2022-12-20-bipoisson/index.html#dados",
    "title": "Predições de Resultados de Futebol",
    "section": "Dados",
    "text": "Dados\nSerão utilizados dados de partidas entre seleções que estão disponíveis neste repositório: martj42/international_results. A primeira partida disponível na base data de 30/11/1872.\n\ndata &lt;- read_csv(\n  file = \"https://github.com/martj42/international_results/raw/master/results.csv\",\n  show_col_types = FALSE\n)\n\n# Remove partidas sem resultados e ajusta os nomes das variáveis de home e away\n# para team1 e team2\ndata &lt;- data |&gt;\n  filter(!is.na(home_score)) |&gt;\n  rename(\n    team1 = home_team,\n    team2 = away_team,\n    team1_score = home_score,\n    team2_score = away_score\n  )\n\nhead(data)\n\n# A tibble: 6 × 9\n  date       team1    team2    team1_score team2_score tournament city   country\n  &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;  \n1 1872-11-30 Scotland England            0           0 Friendly   Glasg… Scotla…\n2 1873-03-08 England  Scotland           4           2 Friendly   London England\n3 1874-03-07 Scotland England            2           1 Friendly   Glasg… Scotla…\n4 1875-03-06 England  Scotland           2           2 Friendly   London England\n5 1876-03-04 Scotland England            3           0 Friendly   Glasg… Scotla…\n6 1876-03-25 Scotland Wales              4           0 Friendly   Glasg… Scotla…\n# ℹ 1 more variable: neutral &lt;lgl&gt;"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#elo-rating",
    "href": "posts/2022-12-20-bipoisson/index.html#elo-rating",
    "title": "Predições de Resultados de Futebol",
    "section": "Elo Rating",
    "text": "Elo Rating\nO código abaixo irá calcular os scores (rating) do times utilizando o pacote EloRating. A fórmula de atualização dos scores depende um fator atualização \\(k\\). Quanto maior esse valor, maior será o tamanho do ajuste dos scores dos times envolvidos em cada partida. Aqui, será utilizado o valor 20 igual ao adotado por J. James Reade.\n\n# Determina o vencendor e o perdedor\n# Em caso de empate, não importa a ordem, mas é preciso indicar que é um empate\ndata &lt;- data |&gt;\n  mutate(\n    winner = case_when(\n      team1_score &gt;= team2_score ~ team1,\n      TRUE ~ team2\n    ),\n    loser = case_when(\n      team1_score &lt; team2_score ~ team1,\n      TRUE ~ team2\n    ),\n    draw = team1_score == team2_score,\n    match_id = 1:n()\n  )\n\n# Calcula os ratings\nelo_fit &lt;- elo.seq(\n  winner = data$winner,\n  loser = data$loser,\n  Date = data$date,\n  draw = data$draw,\n  k = 20\n)\n\n# Adiciona os ratings ao data.frame.\n# Note que utilizamos o rate do dia anterior à partida para que seja refletido\n# o score de cada time antes da partida.\ndata &lt;- data |&gt;\n  mutate(\n    team1_elo = extract_elo(\n      eloobject = elo_fit,\n      extractdate = pmax(min(elo_fit$truedates), date - 1),\n      IDs = team1\n    ),\n    team2_elo = extract_elo(\n      eloobject = elo_fit,\n      extractdate = pmax(min(elo_fit$truedates), date - 1),\n      IDs = team2\n    )\n  )"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#resultados-por-time",
    "href": "posts/2022-12-20-bipoisson/index.html#resultados-por-time",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Resultados por time",
    "text": "Resultados por time\n\nresults_by_team <- bind_rows(\n  data %>%\n    rename(\n      team = home_team,\n      opponent_team = away_team,\n      score = home_score,\n      opponent_score = away_score,\n      elo = home_team_elo,\n      opponent_elo = away_team_elo\n    ) %>%\n    mutate(\n      team1 = TRUE,\n      diff_score = score - opponent_score\n    ),\n  data %>%\n    rename(\n      team = away_team,\n      opponent_team = home_team,\n      score= away_score,\n      opponent_score = home_score,\n      elo = away_team_elo,\n      opponent_elo = home_team_elo\n    ) %>%\n    mutate(\n      team1 = FALSE,\n      diff_score = score - opponent_score\n    )\n) %>%\n  arrange(date, team)"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#features",
    "href": "posts/2022-12-20-bipoisson/index.html#features",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Features",
    "text": "Features\n\nfeatures <- results_by_team %>%\n  group_by(team) %>%\n  mutate(\n    ht_lag_elo = dplyr::lag(elo, n = 1),\n    # ht_elo_avg_20 = roll_mean(\n    #   x = ht_lag_elo,\n    #   n = 20,\n    #   fill = 1000,\n    #   align = \"right\"\n    # ),\n    ht_score_avg_20 = roll_mean(\n      x = dplyr::lag(score, n = 1),\n      n = 20,\n      fill = 0,\n      align = \"right\"\n    ),\n    ht_opp_score_avg_20 = roll_mean(\n      x = dplyr::lag(opponent_score, n = 1),\n      n = 20,\n      fill = 0,\n      align = \"right\"\n    )\n  ) %>%\n  group_by(opponent_team) %>%\n  mutate(\n    at_lag_elo = dplyr::lag(opponent_elo, n = 1),\n    # at_elo_avg_20 = roll_mean(\n    #   x = at_lag_elo,\n    #   n = 20,\n    #   fill = 1000,\n    #   align = \"right\"\n    # ),\n    at_score_avg_20 = roll_mean(\n      x = dplyr::lag(opponent_score, n = 1),\n      n = 20,\n      fill = 0,\n      align = \"right\"\n    ),\n    at_opp_score_avg_20 = roll_mean(\n      x = dplyr::lag(score, n = 1),\n      n = 20,\n      fill = 0,\n      align = \"right\"\n    )\n  ) %>%\n  ungroup() %>%\n  mutate(\n    elo_relative = ht_lag_elo / at_lag_elo\n  ) %>%\n  filter(team1) %>%\n  select(match_id, contains(\"lag\"), elo_relative, contains(\"avg\"))"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#dados-para-o-modelo",
    "href": "posts/2022-12-20-bipoisson/index.html#dados-para-o-modelo",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Dados para o modelo",
    "text": "Dados para o modelo\n\ndata <- data %>%\n  mutate(\n    target = case_when(\n      home_score > away_score ~ \"home\",\n      home_score < away_score ~ \"away\",\n      home_score == away_score ~ \"draw\"\n    ),\n    target = factor(target, levels = c(\"home\", \"draw\", \"away\")),\n    friendly = tournament == \"Friendly\",\n    world_cup = tournament == \"FIFA World Cup\"\n  ) %>%\n  select(\n    match_id, date, home_team, away_team, target, neutral, friendly, tournament,\n    world_cup\n  ) %>%\n  dplyr::left_join(\n    y = features,\n    by = \"match_id\"\n  )"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#treino-validação-e-teste",
    "href": "posts/2022-12-20-bipoisson/index.html#treino-validação-e-teste",
    "title": "Predições de Resultados de Futebol",
    "section": "Treino, validação e teste",
    "text": "Treino, validação e teste\nComo não vamos realizar nenhuma seleção de hiperparâmetros, já que o modelo é bastante simples, iremos dividir os dados apenas em dois conjuntos: treino e teste.\n\ndata &lt;- data |&gt;\n  mutate(friendly = tournament == \"Friendly\") |&gt;\n  filter(date &gt;= as.Date(\"1930-01-01\"))\n\n# Split - Treino e Teste\ntrain_test &lt;- initial_time_split(data, prop = 0.8)\ntrain &lt;- training(train_test)\ntest &lt;- testing(train_test)"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#workflow",
    "href": "posts/2022-12-20-bipoisson/index.html#workflow",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Workflow",
    "text": "Workflow\n\npreproc <- recipe(target ~ ., data = train_full) %>%\n  step_rm(match_id, date, tournament)\n\nmodel <- boost_tree(\n  mode = \"classification\",\n  learn_rate = 0.01,\n  mtry = tune(),\n  trees = tune(),\n  tree_depth = tune(),\n  sample_size = tune()\n) %>%\n  set_engine(engine = \"lightgbm\", num_threads = 16, count = FALSE)\n\nwflow <- workflow(preproc, model)"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#fit",
    "href": "posts/2022-12-20-bipoisson/index.html#fit",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Fit",
    "text": "Fit\n\ntune_grid(\n  object = wflow,\n  resamples = train_valid,\n  metrics = metric_set(mn_log_loss)\n) %>%\n  show_best()\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n# A tibble: 5 × 9\n   mtry trees tree_depth .metric     .estimator  mean     n std_err .config     \n  <int> <int>      <int> <chr>       <chr>      <dbl> <int>   <dbl> <chr>       \n1     2  1102          2 mn_log_loss multiclass 0.918     1      NA Preprocesso…\n2     1    15          4 mn_log_loss multiclass 0.932     1      NA Preprocesso…\n3     4   241         13 mn_log_loss multiclass 0.941     1      NA Preprocesso…\n4     4   484         10 mn_log_loss multiclass 0.976     1      NA Preprocesso…\n5     5   628         12 mn_log_loss multiclass 0.999     1      NA Preprocesso…"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#grid-search",
    "href": "posts/2022-12-20-bipoisson/index.html#grid-search",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Grid Search",
    "text": "Grid Search\n\nset.seed(32)\n\nparam_grid <- expand.grid(\n  mtry = c(0.1, 0.5, 0.9),\n  trees = seq(100, 1000, 100),\n  tree_depth = c(2, 4, 6),\n  sample_size = c(0.1, 0.5, 0.9)\n)\n\nres_grid <- tune_grid(\n  object = wflow,\n  resamples = train_valid,\n  metrics = metric_set(mn_log_loss),\n  grid = param_grid\n)\n\nshow_best(res_grid)\n\n# A tibble: 5 × 10\n   mtry trees tree_depth sample_size .metric .esti…¹  mean     n std_err .config\n  <dbl> <dbl>      <dbl>       <dbl> <chr>   <chr>   <dbl> <int>   <dbl> <chr>  \n1   0.1  1000          6         0.1 mn_log… multic… 0.900     1      NA Prepro…\n2   0.1   900          6         0.1 mn_log… multic… 0.900     1      NA Prepro…\n3   0.1   700          6         0.1 mn_log… multic… 0.900     1      NA Prepro…\n4   0.1   800          6         0.1 mn_log… multic… 0.900     1      NA Prepro…\n5   0.1  1000          4         0.1 mn_log… multic… 0.900     1      NA Prepro…\n# … with abbreviated variable name ¹​.estimator"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#fit-final-model",
    "href": "posts/2022-12-20-bipoisson/index.html#fit-final-model",
    "title": "Predição de resultados de futebol - Parte 1",
    "section": "Fit Final Model",
    "text": "Fit Final Model\n\nset.seed(32)\n\nbest_config <- select_best(res_grid)\n\nwflow <- wflow %>%\n  finalize_workflow(best_config)\n\nwflow <- fit(wflow, train_full)\nwc2022_matches <- test %>%\n  filter(date > as.Date(\"2022-01-01\"), tournament == \"FIFA World Cup\")\n\npred <- predict(object = wflow, wc2022_matches)\npred_probs <- predict(object = wflow, wc2022_matches, type = \"prob\")\n\nbind_cols(wc2022_matches, pred, pred_probs) %>%\n  accuracy(\n    truth = target,\n    estimate = .pred_class\n  )\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.531\n\n\n\nbind_cols(wc2022_matches, pred, pred_probs) %>%\n  select(date, home_team, away_team, target, contains(\".pred\")) %>%\n  mutate(correct = target == .pred_class) %>%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nhome_team\naway_team\ntarget\n.pred_class\n.pred_home\n.pred_draw\n.pred_away\ncorrect\n\n\n\n\n2022-11-20\nQatar\nEcuador\naway\nhome\n0.4310823\n0.2745520\n0.2943657\nFALSE\n\n\n2022-11-21\nSenegal\nNetherlands\naway\naway\n0.1793220\n0.1702988\n0.6503792\nTRUE\n\n\n2022-11-21\nEngland\nIran\nhome\nhome\n0.4419850\n0.3223231\n0.2356918\nTRUE\n\n\n2022-11-21\nUnited States\nWales\ndraw\nhome\n0.4700064\n0.2579292\n0.2720645\nFALSE\n\n\n2022-11-22\nArgentina\nSaudi Arabia\naway\nhome\n0.7094082\n0.1754999\n0.1150920\nFALSE\n\n\n2022-11-22\nMexico\nPoland\ndraw\nhome\n0.4418692\n0.2744693\n0.2836615\nFALSE\n\n\n2022-11-22\nDenmark\nTunisia\ndraw\nhome\n0.6261779\n0.2317065\n0.1421157\nFALSE\n\n\n2022-11-22\nFrance\nAustralia\nhome\nhome\n0.6310226\n0.1940395\n0.1749379\nTRUE\n\n\n2022-11-23\nGermany\nJapan\naway\nhome\n0.5536771\n0.2029826\n0.2433403\nFALSE\n\n\n2022-11-23\nSpain\nCosta Rica\nhome\nhome\n0.7078843\n0.1527469\n0.1393689\nTRUE\n\n\n2022-11-23\nMorocco\nCroatia\ndraw\naway\n0.2955139\n0.2543549\n0.4501313\nFALSE\n\n\n2022-11-23\nBelgium\nCanada\nhome\nhome\n0.6211175\n0.1730603\n0.2058222\nTRUE\n\n\n2022-11-24\nSwitzerland\nCameroon\nhome\nhome\n0.5491011\n0.2575750\n0.1933239\nTRUE\n\n\n2022-11-24\nBrazil\nSerbia\nhome\nhome\n0.7349171\n0.1319857\n0.1330972\nTRUE\n\n\n2022-11-24\nUruguay\nSouth Korea\ndraw\nhome\n0.3973462\n0.3712340\n0.2314198\nFALSE\n\n\n2022-11-24\nPortugal\nGhana\nhome\nhome\n0.7045217\n0.1491760\n0.1463023\nTRUE\n\n\n2022-11-25\nQatar\nSenegal\naway\naway\n0.3433381\n0.2712964\n0.3853655\nTRUE\n\n\n2022-11-25\nNetherlands\nEcuador\ndraw\nhome\n0.6636072\n0.2113182\n0.1250745\nFALSE\n\n\n2022-11-25\nWales\nIran\naway\naway\n0.2218286\n0.2532843\n0.5248871\nTRUE\n\n\n2022-11-25\nEngland\nUnited States\ndraw\nhome\n0.6379013\n0.2101282\n0.1519705\nFALSE\n\n\n2022-11-26\nPoland\nSaudi Arabia\nhome\nhome\n0.4914292\n0.2835209\n0.2250499\nTRUE\n\n\n2022-11-26\nArgentina\nMexico\nhome\nhome\n0.6279036\n0.2106612\n0.1614352\nTRUE\n\n\n2022-11-26\nTunisia\nAustralia\naway\naway\n0.3594266\n0.2316107\n0.4089628\nTRUE\n\n\n2022-11-26\nFrance\nDenmark\nhome\nhome\n0.5032890\n0.2216918\n0.2750192\nTRUE\n\n\n2022-11-27\nJapan\nCosta Rica\naway\nhome\n0.5021156\n0.2840079\n0.2138765\nFALSE\n\n\n2022-11-27\nSpain\nGermany\ndraw\nhome\n0.5130638\n0.1619865\n0.3249497\nFALSE\n\n\n2022-11-27\nBelgium\nMorocco\naway\nhome\n0.5285866\n0.2673819\n0.2040315\nFALSE\n\n\n2022-11-27\nCroatia\nCanada\nhome\nhome\n0.5295668\n0.2801163\n0.1903169\nTRUE\n\n\n2022-11-28\nCameroon\nSerbia\ndraw\naway\n0.2707981\n0.2041036\n0.5250983\nFALSE\n\n\n2022-11-28\nBrazil\nSwitzerland\nhome\nhome\n0.6226013\n0.2182976\n0.1591011\nTRUE\n\n\n2022-11-28\nSouth Korea\nGhana\naway\nhome\n0.6040497\n0.2242025\n0.1717478\nFALSE\n\n\n2022-11-28\nPortugal\nUruguay\nhome\nhome\n0.5028577\n0.2429746\n0.2541676\nTRUE\n\n\n2022-11-29\nEcuador\nSenegal\naway\nhome\n0.4441753\n0.3047349\n0.2510898\nFALSE\n\n\n2022-11-29\nQatar\nNetherlands\naway\naway\n0.1575620\n0.1685282\n0.6739099\nTRUE\n\n\n2022-11-29\nWales\nEngland\naway\naway\n0.1057994\n0.1623531\n0.7318475\nTRUE\n\n\n2022-11-29\nIran\nUnited States\naway\nhome\n0.4985331\n0.2720620\n0.2294049\nFALSE\n\n\n2022-11-30\nPoland\nArgentina\naway\naway\n0.2304773\n0.2189028\n0.5506199\nTRUE\n\n\n2022-11-30\nSaudi Arabia\nMexico\naway\naway\n0.2771191\n0.2416616\n0.4812193\nTRUE\n\n\n2022-11-30\nAustralia\nDenmark\nhome\naway\n0.2725746\n0.2392350\n0.4881903\nFALSE\n\n\n2022-11-30\nTunisia\nFrance\nhome\naway\n0.1706421\n0.2261163\n0.6032416\nFALSE\n\n\n2022-12-01\nJapan\nSpain\nhome\naway\n0.1738116\n0.2886364\n0.5375520\nFALSE\n\n\n2022-12-01\nCosta Rica\nGermany\naway\naway\n0.2088879\n0.2083778\n0.5827343\nTRUE\n\n\n2022-12-01\nCroatia\nBelgium\ndraw\nhome\n0.3617373\n0.2977371\n0.3405257\nFALSE\n\n\n2022-12-01\nCanada\nMorocco\naway\naway\n0.2550098\n0.2989705\n0.4460197\nTRUE\n\n\n2022-12-02\nSerbia\nSwitzerland\naway\naway\n0.2963481\n0.2716211\n0.4320308\nTRUE\n\n\n2022-12-02\nCameroon\nBrazil\nhome\naway\n0.1219967\n0.1503555\n0.7276478\nFALSE\n\n\n2022-12-02\nGhana\nUruguay\naway\naway\n0.1900392\n0.2384322\n0.5715286\nTRUE\n\n\n2022-12-02\nSouth Korea\nPortugal\nhome\naway\n0.2144913\n0.2769087\n0.5086000\nFALSE\n\n\n2022-12-03\nNetherlands\nUnited States\nhome\nhome\n0.6390219\n0.2094897\n0.1514884\nTRUE\n\n\n2022-12-03\nArgentina\nAustralia\nhome\nhome\n0.6573026\n0.1878852\n0.1548122\nTRUE\n\n\n2022-12-04\nFrance\nPoland\nhome\nhome\n0.5707348\n0.2106941\n0.2185710\nTRUE\n\n\n2022-12-04\nEngland\nSenegal\nhome\nhome\n0.5697314\n0.2478583\n0.1824103\nTRUE\n\n\n2022-12-05\nJapan\nCroatia\ndraw\naway\n0.2919517\n0.3078877\n0.4001607\nFALSE\n\n\n2022-12-05\nBrazil\nSouth Korea\nhome\nhome\n0.6207804\n0.2112239\n0.1679957\nTRUE\n\n\n2022-12-06\nMorocco\nSpain\ndraw\naway\n0.2503555\n0.2840146\n0.4656299\nFALSE\n\n\n2022-12-06\nPortugal\nSwitzerland\nhome\nhome\n0.4744534\n0.2872891\n0.2382575\nTRUE\n\n\n2022-12-09\nCroatia\nBrazil\ndraw\naway\n0.2005459\n0.2440647\n0.5553893\nFALSE\n\n\n2022-12-09\nNetherlands\nArgentina\ndraw\nhome\n0.3967020\n0.2356995\n0.3675985\nFALSE\n\n\n2022-12-10\nMorocco\nPortugal\nhome\naway\n0.2922557\n0.2504336\n0.4573107\nFALSE\n\n\n2022-12-10\nEngland\nFrance\naway\naway\n0.3601229\n0.2595121\n0.3803650\nTRUE\n\n\n2022-12-13\nArgentina\nCroatia\nhome\nhome\n0.5383014\n0.2662065\n0.1954920\nTRUE\n\n\n2022-12-14\nFrance\nMorocco\nhome\nhome\n0.5309887\n0.3032172\n0.1657942\nTRUE\n\n\n2022-12-17\nCroatia\nMorocco\nhome\ndraw\n0.3778026\n0.3966415\n0.2255559\nFALSE\n\n\n2022-12-18\nArgentina\nFrance\ndraw\nhome\n0.4396670\n0.2425500\n0.3177829\nFALSE"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#validação",
    "href": "posts/2022-12-20-bipoisson/index.html#validação",
    "title": "Predições de Resultados de Futebol",
    "section": "Validação",
    "text": "Validação\n\nfit1 <- glm(team1_score ~ team1_elo + team2_elo + neutral, data = train, family = \"poisson\")\nsummary(fit1)\n\n\nCall:\nglm(formula = team1_score ~ team1_elo + team2_elo + neutral, \n    family = \"poisson\", data = train)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.1873  -1.1104  -0.2373   0.5344  10.4309  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.509e+00  5.096e-02  29.601  < 2e-16 ***\nteam1_elo    2.031e-03  3.971e-05  51.136  < 2e-16 ***\nteam2_elo   -2.967e-03  3.911e-05 -75.865  < 2e-16 ***\nneutralTRUE -8.510e-02  1.072e-02  -7.942 1.98e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 46656  on 27579  degrees of freedom\nResidual deviance: 39895  on 27576  degrees of freedom\nAIC: 94768\n\nNumber of Fisher Scoring iterations: 5\n\npred1 <- predict(fit1, valid, type = \"response\")\n\nfit2 <- glm(team2_score ~ team1_elo + team2_elo + neutral, data = train, family = \"poisson\")\nsummary(fit2)\n\n\nCall:\nglm(formula = team2_score ~ team1_elo + team2_elo + neutral, \n    family = \"poisson\", data = train)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.8560  -1.2868  -0.2057   0.5046   8.2971  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  7.282e-01  6.273e-02   11.61   <2e-16 ***\nteam1_elo   -2.925e-03  4.768e-05  -61.34   <2e-16 ***\nteam2_elo    2.273e-03  4.951e-05   45.92   <2e-16 ***\nneutralTRUE  2.898e-01  1.230e-02   23.57   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 42429  on 27579  degrees of freedom\nResidual deviance: 37430  on 27576  degrees of freedom\nAIC: 79843\n\nNumber of Fisher Scoring iterations: 5\n\npred2 <- predict(fit2, valid, type = \"response\")\n\n\npreds <- map_df(seq_len(nrow(valid)), ~{\n  lambda1 <- pred1[.x]\n  lambda2 <- pred2[.x]\n\n  prob1 <- dpois(0:10, lambda1)\n  prob2 <- dpois(0:10, lambda2)\n  probs <- outer(prob1, prob2)\n  probs <- probs / sum(probs)\n\n  prob_team1 <- sum(lower.tri(probs) * probs)\n  prob_team2 <- sum(upper.tri(probs) * probs)\n  prob_draw <- sum(diag(probs))\n\n  data.frame(\n    .pred_team1 = prob_team1,\n    .pred_draw = prob_draw,\n    .pred_team2 = prob_team2\n  )\n})\n\n\nvalid |>\n  bind_cols(preds) |>\n  mutate(\n    target = case_when(\n      team1_score > team2_score ~ \"team1\",\n      team1_score == team2_score ~ \"draw\",\n      team1_score < team2_score ~ \"team2\"\n    ),\n    target = factor(target, c(\"team1\", \"draw\", \"team2\"))\n  ) |>\n  mn_log_loss(\n    truth = target,\n    estimate = contains(\"pred\")\n  )\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 mn_log_loss multiclass     0.911"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#teste",
    "href": "posts/2022-12-20-bipoisson/index.html#teste",
    "title": "Predições de Resultados de Futebol",
    "section": "Teste",
    "text": "Teste\n\nfit1 <- glm(team1_score ~ team1_elo + team2_elo + neutral, data = train_full, family = \"poisson\")\nsummary(fit1)\n\n\nCall:\nglm(formula = team1_score ~ team1_elo + team2_elo + neutral, \n    family = \"poisson\", data = train_full)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.3123  -1.1426  -0.2357   0.5326  10.5104  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.448e+00  4.271e-02  33.913  < 2e-16 ***\nteam1_elo    1.989e-03  3.394e-05  58.599  < 2e-16 ***\nteam2_elo   -2.893e-03  3.351e-05 -86.319  < 2e-16 ***\nneutralTRUE -7.496e-02  9.571e-03  -7.832 4.79e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 58034  on 34475  degrees of freedom\nResidual deviance: 49451  on 34472  degrees of freedom\nAIC: 117216\n\nNumber of Fisher Scoring iterations: 5\n\npred1 <- predict(fit1, test, type = \"response\")\n\nfit2 <- glm(team2_score ~ team1_elo + team2_elo + neutral, data = train_full, family = \"poisson\")\nsummary(fit2)\n\n\nCall:\nglm(formula = team2_score ~ team1_elo + team2_elo + neutral, \n    family = \"poisson\", data = train_full)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.8221  -1.2718  -0.2035   0.4967   8.3455  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  5.932e-01  5.231e-02   11.34   <2e-16 ***\nteam1_elo   -2.864e-03  4.078e-05  -70.23   <2e-16 ***\nteam2_elo    2.319e-03  4.193e-05   55.31   <2e-16 ***\nneutralTRUE  3.028e-01  1.097e-02   27.61   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 52760  on 34475  degrees of freedom\nResidual deviance: 46153  on 34472  degrees of freedom\nAIC: 98597\n\nNumber of Fisher Scoring iterations: 5\n\npred2 <- predict(fit2, test, type = \"response\")\n\n\npreds <- map_df(seq_len(nrow(test)), ~{\n  lambda1 <- pred1[.x]\n  lambda2 <- pred2[.x]\n\n  prob1 <- dpois(0:10, lambda1)\n  prob2 <- dpois(0:10, lambda2)\n  probs <- outer(prob1, prob2)\n  probs <- probs / sum(probs)\n\n  prob_team1 <- sum(lower.tri(probs) * probs)\n  prob_team2 <- sum(upper.tri(probs) * probs)\n  prob_draw <- sum(diag(probs))\n\n  data.frame(\n    .pred_team1 = prob_team1,\n    .pred_draw = prob_draw,\n    .pred_team2 = prob_team2\n  )\n})\n\n\ntest |>\n  bind_cols(preds) |>\n  mutate(\n    target = case_when(\n      team1_score > team2_score ~ \"team1\",\n      team1_score == team2_score ~ \"draw\",\n      team1_score < team2_score ~ \"team2\"\n    ),\n    target = factor(target, c(\"team1\", \"draw\", \"team2\"))\n  ) |>\n  mn_log_loss(\n    truth = target,\n    estimate = contains(\"pred\")\n  )\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 mn_log_loss multiclass     0.902\n\n\n\ntest |>\n  bind_cols(preds) |>\n  mutate(\n    target = case_when(\n      team1_score > team2_score ~ \"team1\",\n      team1_score == team2_score ~ \"draw\",\n      team1_score < team2_score ~ \"team2\"\n    ),\n    target = factor(target, c(\"team1\", \"draw\", \"team2\")),\n    pred_class = case_when(\n      .pred_team1 == pmax(.pred_team1, .pred_team2, .pred_draw) ~ \"team1\",\n      .pred_draw == pmax(.pred_team1, .pred_team2, .pred_draw) ~ \"draw\",\n      .pred_team2 == pmax(.pred_team1, .pred_team2, .pred_draw) ~ \"team2\"\n    ),\n    pred_class = factor(pred_class, c(\"team1\", \"draw\", \"team2\"))\n  ) |>\n  filter(date >= as.Date(\"2022-01-01\"), tournament == \"FIFA World Cup\") |>\n  # select(date, team1, team2, target, pred_class)\n  accuracy(\n    truth = target,\n    estimate = pred_class\n  )\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.531\n\n  # mn_log_loss(\n  #   truth = target,\n  #   estimate = contains(\"pred\")\n  # )"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#pacotes",
    "href": "posts/2022-12-20-bipoisson/index.html#pacotes",
    "title": "Predições de Resultados de Futebol",
    "section": "Pacotes",
    "text": "Pacotes\nOs pacotes utilizados estão listados abaixo.\n\nlibrary(EloRating)\nlibrary(tidymodels)\nlibrary(tidyverse)\n\n# Tema para os gráficos\ntheme_set(theme_bw())"
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#resultados",
    "href": "posts/2022-12-20-bipoisson/index.html#resultados",
    "title": "Predições de Resultados de Futebol",
    "section": "Resultados",
    "text": "Resultados\nNeste primeiro bloco de código, os modelos para os times 1 e 2 são estimados usando a função glm() com a opção family = poisson.\n\nfit1 &lt;- glm(\n  formula = team1_score ~ team1_elo + team2_elo + neutral,\n  data = train,\n  family = \"poisson\"\n)\n\nsummary(fit1)\n\npred1 &lt;- predict(fit1, test, type = \"response\")\n\nfit2 &lt;- glm(\n  formula = team2_score ~ team1_elo + team2_elo + neutral,\n  data = train,\n  family = \"poisson\"\n)\nsummary(fit2)\n\npred2 &lt;- predict(fit2, test, type = \"response\")\n\n\nCall:\nglm(formula = team1_score ~ team1_elo + team2_elo + neutral, \n    family = \"poisson\", data = train)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.412e+00  4.211e-02  33.528  &lt; 2e-16 ***\nteam1_elo    2.005e-03  3.357e-05  59.716  &lt; 2e-16 ***\nteam2_elo   -2.876e-03  3.315e-05 -86.761  &lt; 2e-16 ***\nneutralTRUE -7.586e-02  9.508e-03  -7.979 1.48e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 58873  on 35068  degrees of freedom\nResidual deviance: 50166  on 35065  degrees of freedom\nAIC: 119035\n\nNumber of Fisher Scoring iterations: 5\n\n\nCall:\nglm(formula = team2_score ~ team1_elo + team2_elo + neutral, \n    family = \"poisson\", data = train)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  5.695e-01  5.158e-02   11.04   &lt;2e-16 ***\nteam1_elo   -2.847e-03  4.023e-05  -70.75   &lt;2e-16 ***\nteam2_elo    2.324e-03  4.139e-05   56.14   &lt;2e-16 ***\nneutralTRUE  2.990e-01  1.089e-02   27.45   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 53631  on 35068  degrees of freedom\nResidual deviance: 46925  on 35065  degrees of freedom\nAIC: 100215\n\nNumber of Fisher Scoring iterations: 5\n\n\nNeste segundo bloco, são computadas as probabilidades de vitória do time 1, empate e vitória do time 2. Para isso, são utilizadas as predições anteriores como o parâmetro (\\(\\lambda\\)) da distribuição de Poisson e são calculadas as probabilidades de cada time marcar 0 a 10 gols. Multiplicando as probabilidades são obtidas as probabilidades de cada placar possível. Por último, a probabilidade do time 1 ganhar é calculada como a soma das probabilidades dos placares nos quais o time 1 marca mais gols que o time2. As probabilidades de empate e vitória do time 2 são calculadas de forma similar.\n\npreds &lt;- map_df(seq_len(nrow(test)), ~ {\n  lambda1 &lt;- pred1[.x]\n  lambda2 &lt;- pred2[.x]\n\n  prob1 &lt;- dpois(0:10, lambda1)\n  prob2 &lt;- dpois(0:10, lambda2)\n  probs &lt;- outer(prob1, prob2)\n  probs &lt;- probs / sum(probs)\n\n  prob_team1 &lt;- sum(lower.tri(probs) * probs)\n  prob_team2 &lt;- sum(upper.tri(probs) * probs)\n  prob_draw &lt;- sum(diag(probs))\n\n  data.frame(\n    .pred_team1 = prob_team1,\n    .pred_draw = prob_draw,\n    .pred_team2 = prob_team2\n  )\n})\n\nO código abaixo computa algumas métricas (log-loss e acurácia) para a base de testes.\n\n# Junta as predições aos dados de teste, cria a variável de target e a predição\n# por classe.\ntest &lt;- test |&gt;\n  bind_cols(preds) |&gt;\n  mutate(\n    target = case_when(\n      team1_score &gt; team2_score ~ \"team1\",\n      team1_score == team2_score ~ \"draw\",\n      team1_score &lt; team2_score ~ \"team2\"\n    ),\n    target = factor(target, c(\"team1\", \"draw\", \"team2\")),\n    # predição por classe\n    pred_class = case_when(\n      .pred_team1 == pmax(.pred_team1, .pred_team2, .pred_draw) ~ \"team1\",\n      .pred_draw == pmax(.pred_team1, .pred_team2, .pred_draw) ~ \"draw\",\n      .pred_team2 == pmax(.pred_team1, .pred_team2, .pred_draw) ~ \"team2\"\n    ),\n    pred_class = factor(pred_class, c(\"team1\", \"draw\", \"team2\"))\n  )\n\nscore_acc &lt;- accuracy(\n  data = test,\n  truth = target,\n  estimate = pred_class\n)\n\nscore_ll &lt;- mn_log_loss(\n  data = test,\n  truth = target,\n  contains(\".pred\")\n)\n\nbind_rows(score_acc, score_ll)\n\n# A tibble: 2 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy    multiclass     0.588\n2 mn_log_loss multiclass     0.899\n\n\nE qual é o desempenho do modelo para as partidas da Copa do Mundo de 2022?\n\nscore_acc_wc2022 &lt;- accuracy(\n  data = test |&gt;\n    filter(date &gt;= as.Date(\"2022-01-01\"), tournament == \"FIFA World Cup\"),\n  truth = target,\n  estimate = pred_class\n)\n\nscore_ll_wc2022 &lt;- mn_log_loss(\n  data = test |&gt;\n    filter(date &gt;= as.Date(\"2022-01-01\"), tournament == \"FIFA World Cup\"),\n  truth = target,\n  contains(\".pred\")\n)\n\nbind_rows(score_acc_wc2022, score_ll_wc2022)\n\n# A tibble: 2 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy    multiclass     0.531\n2 mn_log_loss multiclass     1.03 \n\n\nVerifica-se uma acurácia de 53,1% e log-loss de 1.03. Estes resultados indicam uma acurácia menor do que aquela obtida para o conjunto total de teste. Por fim, para dar uma sensibilidade da qualidade dos resultados obtidos por esse modelo, deixo aqui uma comparação realizada pelo Octosport:\n\nThe FIFA world cup has just ended. It is time to share our model performance over the 64 games. We reached an accuracy of 56.2% and a log-loss of -0.982 on the final-time winner prediction (90 minutes).For comparison, famous 538 did 53.1% with a log-loss of -1.031 while kickoff.ai did 54.6% and -1.028."
  },
  {
    "objectID": "index.html#olá",
    "href": "index.html#olá",
    "title": "Paulo Oliveira",
    "section": "Olá,",
    "text": "Olá,\nEu sou o Paulo. Minha formação é em economia. Minha área de interesse é análise de dados em geral, como simulação com base em modelos econômicos, econometria e aprendizado de máquina."
  },
  {
    "objectID": "index.html#olá-1",
    "href": "index.html#olá-1",
    "title": "Olá,",
    "section": "Olá,",
    "text": "Olá,\nEu sou o Paulo. Minha formação é em economia. Minha área de interesse é análise de dados em geral, como simulação com base em modelos econômicos, econometria e aprendizado de máquina."
  },
  {
    "objectID": "posts/2023-03-16-binscatter/index.html",
    "href": "posts/2023-03-16-binscatter/index.html",
    "title": "Binscatter",
    "section": "",
    "text": "Neste post, irei tratar sobre o binscatter/binsreg seguindo o trabalho de Cattaneo et al. (2022). Este trabalho discute o gráfico do tipo binscater, que é comumente utilizado como alternativa ao scatterplot tradicional. Esse tipo de gráfico é uma ferramenta bastante útil para a visualização de relação entre duas variáveis. Nesse trabalho, os autores discutem um conjunto de falhas no procedimento usualmente adotado na utilização do binscatter. Adicionalmente, os autores desenvolvem a fundamentação teórica para a chamada regressão binscatter (binsreg), fornecendo um conjunto de procedimentos, como ajustes para covariáveis, testes formais para hipóteses, por exemplo, de linearidade. O método desenvolvido pelos autores também permite que a análise possa envolver variáveis binárias, de contagem e outros tipos de variáveis categóricas."
  },
  {
    "objectID": "posts/2023-03-16-binscatter/index.html#escolha-do-número-de-bins",
    "href": "posts/2023-03-16-binscatter/index.html#escolha-do-número-de-bins",
    "title": "Binscatter",
    "section": "Escolha do número de bins",
    "text": "Escolha do número de bins\nComumente, os números de bins são escolhidos de forma arbitrária, por exemplo, \\(J = 20\\) ou \\(J = 50\\). Cattaneo et al. (2022) propõem um método para escolher o número de bins de forma mais sistemática. Os autores consideram duas abordagens que dependem do objetivo da análise: estimação não-paramétrica ou visualização de dados.\nA primeira opção, \\(J_{IMSE}\\), é baseada no erro quadrático médio integrado (IMSE) ótimo. O número de bins sendo escolhido dessa forma permite a utilização da regressão binscatter para quantificar a incerteza das estimativas geradas. A outra opção, é definir o número de bins \\(J\\) de forma arbitrária, mas escolher a ordem polinomial \\(p\\) da função \\(\\mathbf{b}(x)\\) que minimiza a distância entre \\(J_{IMSE}(p, v)\\) e \\(J\\), em que \\(v\\) é a derivada de interesse da função do valor esperado de \\(y\\) com relação a \\(x\\). Para \\(v = 0\\), a quantidade de interesse é \\(\\mathbb{E}[y_i|x, \\mathbf{w}]\\)."
  },
  {
    "objectID": "posts/2023-06-09-geobr-d3plusr/index.html",
    "href": "posts/2023-06-09-geobr-d3plusr/index.html",
    "title": "Visualizações de mapas interativos com o D3plusR",
    "section": "",
    "text": "Introdução\nEste post tem o objetivo de mostrar a solução encontrada para uma questão levantada no repositório do D3plusR (aqui). O autor da issue gostaria de saber se seria possível integrar as bases de dados espaciais do pacote geobr com o D3plusR. A resposta é sim! E é isso que vamos ver neste post. Apenas uma ressalva, como não sou especialista em dados espaciais, é possível que essa não seja a solução mais eficiente para o problema. Se você tem conhecimento sobre uma solução mais elegante, você pode compartilhar aqui ou no github.\n\n\nPacotes\nAbaixo, estão listados os pacotes utilizados neste post.\n\n# Para instalar o D3plusR:\n# devtools::install_github('paulofelipe/D3plusR')\n\nlibrary(geobr)\nlibrary(geojsonio)\nlibrary(sf)\nlibrary(D3plusR)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(dplyr)\n\n\n\nDados\nPara o exemplo, irei utilizar os dados do Censo 2010 por microrregião disponibilizados pelo IPEA (Ipea Geo). Especificamente, iremos calcular a proporção da população rural em relação ao total por microrregião.\n\ntemp_file <- tempfile()\ndownload.file(\n  url = \"https://www.ipea.gov.br/ipeageo/arquivos/bases/IBGE_CIDADES_MICROREGIAO.xls\",\n  destfile = temp_file,\n  mode = \"wb\"\n)\ndados_censo2010 <- read_excel(\n  path = temp_file,\n  sheet = \"Censo 2010 (Sinopse)\"\n) %>%\n  clean_names() %>%\n  select(\n    codigo_da_microregiao, populacao_residente, populacao_residente_rural\n  ) %>%\n  mutate(prop_rural = populacao_residente_rural / populacao_residente * 100)\n\n\n\nObtendo o mapa\nPara a criação de um geo_map no D3plusR, é preciso de dados no formato topojson. O código abaixo lê os dados espaciais para as microrregiões brasileiras e converte para o formato topojson.\n\n# Prepara o mapa ---------------------------------------------------------------\nmapa <- read_micro_region(year = 2010, simplified = TRUE) %>%\n  st_transform(4326) %>%\n  transmute(id = code_micro, name_micro) %>%\n  topojson_json(\n    object_name = \"BRMI\",\n    geometry = \"polygon\",\n    type = \"GeometryCollection\",\n    quantization = 1e4,\n    crs = 4326\n  ) %>%\n  fromJSON(., simplifyVector = TRUE)\n\n# Cada \"geometria\" precisa ter um id. Adicionamos a partir das propriedades.\nmapa$objects$BRMI$geometries$id <-\n  mapa$objects$BRMI$geometries$properties$id\n\n# Salva o mapa em um arquivo json para uso futuro sem necessidade de repetir\n# o processo acima\nmapa <- write_json(mapa, \"./br_micro.json\")\n\nO código abaixo faz um join com as propriedades da microrregiões para adicionar os nomes de cada microrregião no data.frame dados_censo2010.\n\nmapa <- read_json(\"./br_micro.json\", simplifyVector = TRUE)\n\n\n\nCriando a visualização\nO código abaixo cria a visualização usando o pacote D3plusR. O importante é que a variável indicada como id no data.frame dados_censo2010 tenha os mesmos códigos que estão no arquivo do mapa. No exemplo, são os códigos de microrregiões. Para mais detalhes sobre a utilização do D3plusR, veja este tutorial.\n\n# Join para adicionar o nome das regiões aos dados\ndados_censo2010 <- dados_censo2010 %>%\n  left_join(\n    y = mapa$objects$BRMI$geometries$properties,\n    by = c(\"codigo_da_microregiao\" = \"id\")\n  ) %>%\n  rename(id = codigo_da_microregiao)\n\nhead(dados_censo2010)\n\n# A tibble: 6 × 5\n     id populacao_residente populacao_residente_rural prop_rural name_micro     \n  <dbl>               <dbl>                     <dbl>      <dbl> <chr>          \n1 11001              540320                     85875       15.9 Porto Velho    \n2 11002               71369                     20438       28.6 Guajará-Mirim  \n3 11003              171150                     56535       33.0 Ariquemes      \n4 11004              295466                     92554       31.3 Ji-Paraná      \n5 11005               70184                     40113       57.2 Alvorada D'oes…\n6 11006              228212                     76457       33.5 Cacoal         \n\nd3plus(\n  data = dados_censo2010,\n  type = \"geo_map\",\n  id = \"id\",\n  width = \"100%\",\n  height = 700,\n  percent_var = \"prop_rural\",\n  locale = \"pt_BR\",\n  dictionary = list(prop_rural = \"Proporção da população rural\"),\n) %>%\n  d3plusCoords(mapa, projection = \"equirectangular\") %>%\n  d3plusColor(value = \"prop_rural\") %>%\n  d3plusTooltip(value = \"prop_rural\") %>%\n  d3plusText(value = \"name_micro\") %>%\n  d3plusTitle(\n    value = \"Proporção da população rural por microrregião - 2010\",\n    font = list(size = 28, weight = 900)\n  )"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html",
    "href": "posts/2023-07-16-comex-arrow/index.html",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "",
    "text": "Este post apresenta um exemplo resumido de como:\n\nÉ posssível baixar a base completa de dados de comércio exterior;\nSalvar os arquivos no formato parquet;\nUsar o duckdb para fazer consultas SQL."
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#ajustes-iniciais",
    "href": "posts/2023-07-16-comex-arrow/index.html#ajustes-iniciais",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Ajustes iniciais",
    "text": "Ajustes iniciais\nO código abaixo cria as pastas que irão salvar os arquivos originais e a base de dados no formato parquet.\n\nif not os.path.exists(\"secex_db\"):\n  os.mkdir(\"secex_db\")\n  os.mkdir(\"secex_db/csvs\")\n  os.mkdir(\"secex_db/parquet\")"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#download-dos-dados",
    "href": "posts/2023-07-16-comex-arrow/index.html#download-dos-dados",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Download dos dados",
    "text": "Download dos dados\nO próximo chunk de código lê a página que contém os links para os arquivos da base de dados e filtra apenas os arquivos que contém os dados de exportação e importação. Um detalhe importante é que esta página disponibiliza um arquivo completo para cada fluxo (exportação e importação). Contudo, o código abaixo extrai os links para os arquivos de cada separadamente.\nVeja este link para conhecer todos os dados disponibilizados pela Secretaria de Comércio Exterior.\n\nurl = \"https://www.gov.br/produtividade-e-comercio-exterior/pt-br/assuntos/comercio-exterior/estatisticas/base-de-dados-bruta\"\nhtml = urlopen(url)\nsoup = BeautifulSoup(html, \"html.parser\")\nlinks = soup.find_all(\"a\", href=True)\nlinks = [\n    link[\"href\"] for link in links if re.search(r\"(EXP|IMP)_[0-9]{4}.csv\", link[\"href\"])\n]\nlinks[:5]\n\n['https://balanca.economia.gov.br/balanca/bd/comexstat-bd/ncm/EXP_1997.csv',\n 'https://balanca.economia.gov.br/balanca/bd/comexstat-bd/ncm/EXP_1998.csv',\n 'https://balanca.economia.gov.br/balanca/bd/comexstat-bd/ncm/EXP_1999.csv',\n 'https://balanca.economia.gov.br/balanca/bd/comexstat-bd/ncm/EXP_2000.csv',\n 'https://balanca.economia.gov.br/balanca/bd/comexstat-bd/ncm/EXP_2001.csv']\n\n\nPara cada link, o arquivo csv para cada fluxo e ano é baixado e salvo na pasta secex_db/csvs.\n\nfor link in links:\n    file_name = link.split(\"/\")[-1]\n    file_path = os.path.join(\"secex_db/csvs\", file_name)\n    if not os.path.exists(file_path):\n        with open(file_path, \"wb\") as f:\n            f.write(urlopen(link).read())\n\nPara checagem, abaixo listamos o nome de cinco arquivos baixados.\n\ncsvs = os.listdir(\"secex_db/csvs\")\ncsvs[:5]\n\n['EXP_1997.csv',\n 'EXP_1998.csv',\n 'EXP_1999.csv',\n 'EXP_2000.csv',\n 'EXP_2001.csv']"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#bibliotecas",
    "href": "posts/2023-07-16-comex-arrow/index.html#bibliotecas",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Bibliotecas",
    "text": "Bibliotecas\nAbaixo, estão listadas as bibliotecas utilizadas neste post.\n\nimport pandas as pd\nimport os\nimport shutil\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nimport re\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport pyarrow.dataset as ds\nimport duckdb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# avoid ssl verification error\nimport ssl\n\nssl._create_default_https_context = ssl._create_unverified_context"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#criação-das-pastas",
    "href": "posts/2023-07-16-comex-arrow/index.html#criação-das-pastas",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Criação das pastas",
    "text": "Criação das pastas\nO código abaixo cria as pastas que irão salvar os arquivos originais e a base de dados no formato parquet.\n\nif not os.path.exists(\"secex_db\"):\n    os.mkdir(\"secex_db\")\n    os.mkdir(\"secex_db/csvs\")\n    os.mkdir(\"secex_db/parquet\")"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#leitura-dos-arquivos-csv",
    "href": "posts/2023-07-16-comex-arrow/index.html#leitura-dos-arquivos-csv",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Leitura dos arquivos csv",
    "text": "Leitura dos arquivos csv\nCom os dados já baixados, o próximo passo será ler os arquivos csv e salvar no formato parquet. Para isso, utilizaremos o pacote pyarrow.\n\n# Limpa as pastas caso já existam arquivos criados\nif os.path.exists(\"secex_db/parquet/EXP/\"):\n    for folder in os.listdir(\"secex_db/parquet/EXP/\"):\n        shutil.rmtree(f\"secex_db/parquet/EXP/{folder}\")\n\nif os.path.exists(\"secex_db/parquet/IMP/\"):\n    for folder in os.listdir(\"secex_db/parquet/IMP/\"):\n        shutil.rmtree(f\"secex_db/parquet/IMP/{folder}\")\n\nfor csv in csvs:\n    df = pd.read_csv(\n        filepath_or_buffer=f\"secex_db/csvs/{csv}\",\n        sep=\";\",\n        encoding=\"latin-1\",\n        low_memory=False,\n        dtype={\n            \"CO_ANO\": \"int16\",\n            \"CO_MES\": \"int16\",\n            \"CO_NCM\": \"string\",\n            \"CO_UNID\": \"string\",\n            \"CO_PAIS\": \"string\",\n            \"SG_UF_NCM\": \"string\",\n            \"CO_VIA\": \"string\",\n            \"CO_URF\": \"string\",\n            \"QT_ESTAT\": \"float32\",\n            \"KG_LIQUIDO\": \"float32\",\n            \"VL_FOB\": \"float32\",\n        },\n    )\n    if \"EXP\" in csv:\n        pq.write_to_dataset(\n            pa.Table.from_pandas(df),\n            root_path=\"secex_db/parquet/EXP/\",\n            partition_cols=[\"CO_ANO\"],\n        )\n    else:\n        pq.write_to_dataset(\n            pa.Table.from_pandas(df),\n            root_path=\"secex_db/parquet/IMP/\",\n            partition_cols=[\"CO_ANO\"],\n        )"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#arrow-datasets",
    "href": "posts/2023-07-16-comex-arrow/index.html#arrow-datasets",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Arrow datasets",
    "text": "Arrow datasets\nCom os arquivos salvos no formato parquet, podemos criar os datasets do pyarrow para cada fluxo (exportação e importação). Um ponto importante do dataset é que ele permite trabalhar com dados que podem ser maiores do que a memória disponível no seu computador. Ao abrir o dataset, o pyarrow apenas irá mapear a estrutura dos dados, sem carregá-los na memória.\n\nexp_ds = ds.dataset(\"secex_db/parquet/EXP\", format=\"parquet\", partitioning=\"hive\")\nexp_ds.schema\n\nCO_MES: int16\nCO_NCM: string\nCO_UNID: string\nCO_PAIS: string\nSG_UF_NCM: string\nCO_VIA: string\nCO_URF: string\nQT_ESTAT: float\nKG_LIQUIDO: float\nVL_FOB: float\nCO_ANO: int32\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 1515\n\n\n\nimp_ds = ds.dataset(\"secex_db/parquet/IMP\", format=\"parquet\", partitioning=\"hive\")\nimp_ds.schema\n\nCO_MES: int16\nCO_NCM: string\nCO_UNID: string\nCO_PAIS: string\nSG_UF_NCM: string\nCO_VIA: string\nCO_URF: string\nQT_ESTAT: float\nKG_LIQUIDO: float\nVL_FOB: float\nVL_FRETE: int64\nVL_SEGURO: int64\nCO_ANO: int32\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 1743"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#realizando-consultas",
    "href": "posts/2023-07-16-comex-arrow/index.html#realizando-consultas",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Realizando consultas",
    "text": "Realizando consultas\nA biblioteca duckdb permite realizar consultas SQL diretamente nos datasets do Arrow. O duckdb irá fazer uma integração com o Arrow sem a necessidade copiar os dados. Para mais detalhes, veja este post.\n\nExemplo 1: Obtendo os totais de exportação e importação por ano\nCria a conexão com o duckdb.\n\ncon = duckdb.connect()\n\nNo código seguinte, é apresentado como é simples realizar consultas nos datasets exp_ds e imp_ds. As consultas abaixos calculam os totais exportados e importados em US$ Bilhões até o ano de 2022.\n\ntotal_exp = con.execute(\n    \"\"\"SELECT CO_ANO, SUM(VL_FOB / 1E9) AS TOTAL_EXP_BI FROM exp_ds\n     WHERE CO_ANO &lt;= 2022\n     GROUP BY CO_ANO\"\"\"\n).fetch_df()\n\ntotal_imp = con.execute(\n    \"\"\"SELECT CO_ANO, SUM(VL_FOB / 1E9) AS TOTAL_IMP_BI FROM imp_ds\n    WHERE CO_ANO &lt;= 2022\n    GROUP BY CO_ANO\"\"\"\n).fetch_df()\n\nOs dados são combinados em um dataframe único e printados na tabela abaixo.\n\ntotal_exp_imp = (\n    total_exp.merge(total_imp, on=\"CO_ANO\")\n    .sort_values(by=\"CO_ANO\")\n    .reset_index(drop=True)\n)\n\ntotal_exp_imp\n\n\n\n\n\nExportações e importações brasileiras por ano - US$ Bilhões {#a09b851e}\n\n\n\nCO_ANO\nTOTAL_EXP_BI\nTOTAL_IMP_BI\n\n\n\n\n0\n1997\n52.947496\n60.537962\n\n\n1\n1998\n51.076604\n58.672861\n\n\n2\n1999\n47.945909\n50.259540\n\n\n3\n2000\n54.993160\n56.976350\n\n\n4\n2001\n58.032294\n56.569020\n\n\n5\n2002\n60.147158\n48.274764\n\n\n6\n2003\n72.776747\n49.307163\n\n\n7\n2004\n95.121672\n63.813637\n\n\n8\n2005\n118.597835\n74.692216\n\n\n9\n2006\n137.581151\n92.531097\n\n\n10\n2007\n159.816384\n122.041949\n\n\n11\n2008\n195.764624\n174.707088\n\n\n12\n2009\n151.791674\n129.397612\n\n\n13\n2010\n200.434135\n183.336965\n\n\n14\n2011\n253.666310\n227.969757\n\n\n15\n2012\n239.952538\n225.166426\n\n\n16\n2013\n232.544256\n241.500886\n\n\n17\n2014\n220.923237\n230.823019\n\n\n18\n2015\n186.782355\n173.104259\n\n\n19\n2016\n179.526129\n139.321358\n\n\n20\n2017\n214.988108\n158.951444\n\n\n21\n2018\n231.889523\n185.321984\n\n\n22\n2019\n221.126807\n185.927968\n\n\n23\n2020\n209.180242\n158.786825\n\n\n24\n2021\n280.814577\n219.408049\n\n\n25\n2022\n334.136038\n272.610687\n\n\n\n\n\n\n\n\nsns.set(rc={\"figure.figsize\": (8, 5)})\nsns.set_theme(style=\"whitegrid\")\nsns.lineplot(data=total_exp_imp, x=\"CO_ANO\", y=\"TOTAL_EXP_BI\", label=\"Exportação\")\nsns.lineplot(data=total_exp_imp, x=\"CO_ANO\", y=\"TOTAL_IMP_BI\", label=\"Importação\")\nplt.xlabel(\"Ano\")\nplt.ylabel(\"US$ Bilhões\")\nplt.title(\"Exportação e Importação Brasileira\")\nplt.show()\n\n\n\nExportações e importações brasileiras por ano\n\n\n\n\n\n\n\nExemplo 2: Principais produtos (códigos NCM) exportados em 2022\nNeste exemplo, iremos obter os 10 principais produtos exportados pelo Brasil em 2022. Como o dataset exp_ds guarda apenas os códigos, iremos ler a tabela de correlação que está disponível na mesma página que disponibiliza os dados de exportação e importação. A tabela de correlação pode ser acessada aqui.\n\ntabela_ncm = pd.read_csv(\n    \"https://balanca.economia.gov.br/balanca/bd/tabelas/NCM.csv\",\n    sep=\";\",\n    encoding=\"latin-1\",\n    dtype={\"CO_NCM\": \"string\"},\n)\n\nO código abaixo converte o dataframe tabela_ncm para uma tabela do Arrow, o que irá permitir a realização de um join com o dataset exp_ds.\n\nncm_table = pa.Table.from_pandas(tabela_ncm)\nncm_table.schema\n\nCO_NCM: string\nCO_UNID: int64\nCO_SH6: int64\nCO_PPE: double\nCO_PPI: double\nCO_FAT_AGREG: double\nCO_CUCI_ITEM: string\nCO_CGCE_N3: int64\nCO_SIIT: double\nCO_ISIC_CLASSE: int64\nCO_EXP_SUBSET: double\nNO_NCM_POR: string\nNO_NCM_ESP: string\nNO_NCM_ING: string\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 1914\n\n\n\n(\n    con.execute(\n        \"\"\"SELECT exp_ds.CO_NCM, NO_NCM_POR, SUM(VL_FOB / 1E9) AS TOTAL_EXP_BI\n    FROM exp_ds\n    JOIN ncm_table ON exp_ds.CO_NCM = ncm_table.CO_NCM\n    WHERE CO_ANO = 2022\n    GROUP BY exp_ds.CO_NCM, NO_NCM_POR\n    ORDER BY TOTAL_EXP_BI DESC\n    LIMIT 10\"\"\"\n    ).fetch_df()\n)\n\n\n\n\n\n\n\n\nCO_NCM\nNO_NCM_POR\nTOTAL_EXP_BI\n\n\n\n\n0\n12019000\nSoja, mesmo triturada, exceto para semeadura\n46.553260\n\n\n1\n27090010\nÓleos brutos de petróleo\n42.553764\n\n\n2\n26011100\nMinérios de ferro e seus concentrados, exceto ...\n25.734248\n\n\n3\n10059010\nMilho em grão, exceto para semeadura\n12.072360\n\n\n4\n02023000\nCarnes desossadas de bovino, congeladas\n10.916696\n\n\n5\n27101922\nFuel oil\n10.319564\n\n\n6\n17011400\nOutros açúcares de cana\n9.528719\n\n\n7\n09011110\nCafé não torrado, não descafeinado, em grão\n8.511689\n\n\n8\n47032900\nPastas químicas de madeira, à soda ou ao sulfa...\n7.677711\n\n\n9\n23040090\nBagaços e outros resíduos sólidos, da extração...\n7.538183"
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#considerações-finais",
    "href": "posts/2023-07-16-comex-arrow/index.html#considerações-finais",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "Considerações finais",
    "text": "Considerações finais\nNeste post, apresentamos, utilzando a base de dados de comércio exterior do Brasil, como é possível realizar consultas SQL em datasets do Arrow. A biblioteca duckdb permite realizar consultas SQL diretamente nos datasets do Arrow."
  },
  {
    "objectID": "posts/2023-07-16-comex-arrow/index.html#introdução",
    "href": "posts/2023-07-16-comex-arrow/index.html#introdução",
    "title": "Dados de comércio exterior do Brasil com Arrow e Duckdb",
    "section": "",
    "text": "Este post apresenta um exemplo resumido de como:\n\nÉ posssível baixar a base completa de dados de comércio exterior;\nSalvar os arquivos no formato parquet;\nUsar o duckdb para fazer consultas SQL."
  },
  {
    "objectID": "posts/2022-12-20-bipoisson/index.html#introdução",
    "href": "posts/2022-12-20-bipoisson/index.html#introdução",
    "title": "Predições de Resultados de Futebol",
    "section": "",
    "text": "Durante a Copa do Mundo de futebol de 2022, o interesse por predições de resultados de futebol aumentou consideravelmente. Neste sentido, este post irá demonstrar uma abordagem simples que pode gerar resultados razoáveis. O modelo utilizado neste post é baseado no trabalho The Methodology of Red, a Football Forecasting Model from theUniversity of Reading de J. James Reade.\nBasicamente, o autor utiliza um modelo de Poisson para prever as probabilidades de gols marcados por cada time. A partir dessas probabilidades, é possível estimar também a chance de vitória, empate ou derrota de cada time. Como variáveis, iremos utilizar o Elo Rating de cada time e uma variável que indica se o jogo ocorreu em campo neutro ou não. O modelo a ser estimado para cada time é: \\[ Y_{ijt}^n = \\exp\\left(\\alpha^n + \\beta_1^n R_{it} + \\beta_2^n R_{jt} + \\beta_3^n N_{ijt} \\right) \\varepsilon_{ijt}^n,~~~~ n \\in \\{time1, time2\\}, \\] em que \\(Y_{ijt}^n\\) representa o número de gols marcados pelo time \\(n\\) (time 1 ou time2) em uma partida entre o time \\(i\\) (time 1) e o time \\(j\\) (time 2) na data \\(t\\). As variáveis \\(R_{it}\\) e \\(R_{jt}\\) representam, respectivamente, os ratings dos times \\(i\\) e \\(j\\) antes da partida de data \\(t\\). Por último, a variável \\(N_{ijt}\\) é um variável dummy que indica se a partida foi realizada em um campo neutro. Reforçando, iremos estimar dois modelos: um para o time 1 e outro para o time 2."
  }
]